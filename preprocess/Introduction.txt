With the current massive use of social media, information quality becomes an important issue when it comes to news reporting and other sources of factuality checking. Given the hot topics in fake news classification and toxic comments classification, many datasets have been collected, and they cover a wide range of domains. For example, the LIAR dataset was collected from Politifact and covers the political topics, while FEVER which covers scientific topics is collected from Wikipedia. As more and more fake news prevails on social media, it is getting harder for people to distinguish between true news and fake news and people could sometimes easily be misled by the seemingly-true fake news. As a result, different fake news prediction models have developed intending to serve as fake news detectors and help people perform fact-checking. Many state-of-the-art fake news prediction models have achieved satisfying performance and even outperforming humans. This article aims to investigate the characteristics of fake news articles, focusing on selected fake news dataset, and studying how fake news prediction models distinguish between true news and fake news. This allows people to understand how those models differentiate true news and fake news and would also be beneficial for improving the reader's ability in identifying fake news.